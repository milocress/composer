{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6e1c768",
   "metadata": {},
   "source": [
    "# FaceSynthetics with Streaming Dataloader\n",
    "\n",
    "In this notebook, we'll demonstrate a streaming approach to loading our datasets, using Microsoft's FaceSynthetics dataset as an example.\n",
    "\n",
    "Streaming is useful for multi-node setups where workers don't have persistent storage and each element of the dataset must be downloaded exactly once.\n",
    "\n",
    "This tutorial will consist of a few steps:\n",
    "1. obtaining the dataset\n",
    "2. preparing the dataset for streaming\n",
    "    a. (optionally) uploading the dataset to a server\n",
    "3. streaming the dataset to the local machine\n",
    "4. training a model using these datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9fca78",
   "metadata": {},
   "source": [
    "First, let's make sure we've installed our dependencies, note that `mmcv-full` will take some time to unpack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f46743",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mosaicml -U\n",
    "!pip install mmsegmentation -U\n",
    "!pip install mmcv -U\n",
    "!pip install mmcv-full -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13590fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import struct\n",
    "import shutil\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e68890",
   "metadata": {},
   "source": [
    "We'll be using Composer's streaming dataset writer, as well as the composer `DeepLabV3` model, which should help improve our performance even on the small hundred image dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4ddb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from composer.datasets.streaming import StreamingDatasetWriter, StreamingDataset\n",
    "from composer.models.deeplabv3 import ComposerDeepLabV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae588655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from composer import Trainer\n",
    "from composer.models import ComposerModel\n",
    "from composer.optim import DecoupledAdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d481ed",
   "metadata": {},
   "source": [
    "## Getting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da386c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line for the dataset you wish to download (the 100 image dataset is selected by default)\n",
    "!curl https://facesyntheticspubwedata.blob.core.windows.net/iccv-2021/dataset_100.zip > dataset.zip\n",
    "#!curl https://facesyntheticspubwedata.blob.core.windows.net/iccv-2021/dataset_1000.zip > dataset.zip\n",
    "#!curl https://facesyntheticspubwedata.blob.core.windows.net/iccv-2021/dataset_100000.zip > dataset.zip\n",
    "\n",
    "\n",
    "!mkdir ./dataset\n",
    "!unzip dataset.zip -d dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7069fd",
   "metadata": {},
   "source": [
    "## Global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f45ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the location of our dataset\n",
    "in_root = \"./dataset/\"\n",
    "\n",
    "# the location of the \"remote\" streaming dataset. \n",
    "# Upload `out_root` to your cloud storage provider of choice.\n",
    "out_root = \"./sdl\"\n",
    "out_root_train = \"./sdl/train\"\n",
    "out_root_test = \"./sdl/test\"\n",
    "\n",
    "# the location to download the streaming dataset during training\n",
    "local = './local'\n",
    "local_train = './local/train'\n",
    "local_test = './local/test'\n",
    "\n",
    "# dataset parameters\n",
    "shuffle = False\n",
    "num_classes = 255\n",
    "shard_size_limit = 1 << 25\n",
    "tqdm = 1\n",
    "\n",
    "# training hardware parameters\n",
    "device = \"gpu\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0425d05f",
   "metadata": {},
   "source": [
    "Next, we'll make the directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831a0371",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(out_root)\n",
    "os.mkdir(out_root_train)\n",
    "os.mkdir(out_root_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f083524",
   "metadata": {},
   "source": [
    "## Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ff92f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def each(d, m=0, n=100):\n",
    "    for i in range(m, n):\n",
    "        f = '%s/%06d.png' % (d, i)\n",
    "        x = open(f, 'rb').read()\n",
    "\n",
    "        f = '%s/%06d_seg.png' % (d, i)\n",
    "        y = open(f, 'rb').read()\n",
    "\n",
    "        yield {\n",
    "            'i': struct.pack('>q', i),\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e59c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_datasets() -> None:\n",
    "    \"\"\"Create ImageNet1k streaming dataset.\n",
    "\n",
    "    Args:\n",
    "        args (Namespace): Commandline arguments.\n",
    "    \"\"\"\n",
    "    fields = ['i', 'x', 'y']\n",
    "    m, n = 0, 90\n",
    "    with StreamingDatasetWriter(out_root_train, fields, shard_size_limit) as out:\n",
    "        out.write_samples(each(in_root, m, n), use_tqdm=bool(tqdm), total=n-m)\n",
    "    m, n = n, 100\n",
    "    with StreamingDatasetWriter(out_root_test, fields, shard_size_limit) as out:\n",
    "        out.write_samples(each(in_root, m, n), use_tqdm=bool(tqdm), total=n-m)\n",
    "    shuffle = True\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810dc5d9",
   "metadata": {},
   "source": [
    "Now that we've written the datasets to `out_root`, we can upload them to a cloud storage provider and stream them from there. For the sake of simplicity, we'll skip this step, but the rest of this tutorial will work if we replace `remote` with the URL of a cloud storage directory for the files we've just generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bfa9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_train = out_root_train # replace this with your URL for cloud streaming\n",
    "remote_test = out_root_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dc2143",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b808738",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceSynthetics(StreamingDataset):\n",
    "    def __init__(self,\n",
    "                 remote: str,\n",
    "                 local: str,\n",
    "                 shuffle: bool) -> None:\n",
    "        decoders = {\n",
    "            'i': lambda data: struct.unpack('>q', data),\n",
    "            'x': lambda data: Image.open(BytesIO(data), formats=['PNG']),\n",
    "            'y': lambda data: Image.open(BytesIO(data), formats=['PNG']),\n",
    "        }\n",
    "        super().__init__(local=local, remote=remote, shuffle=shuffle, decoders=decoders)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        obj = super().__getitem__(i)\n",
    "        x = obj['x']\n",
    "        x = tf.ToTensor()(x).to(device)\n",
    "        y = obj['y']\n",
    "        y = tf.ToTensor()(y).to(device)\n",
    "        y_shape = list(y.shape)[:]\n",
    "        y_shape[0] = num_classes # expand y to be a one-hot vector\n",
    "        y_onehot = F.one_hot(y.to(torch.int64), num_classes).view(y_shape).to(device)\n",
    "        return x, y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa5a52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders():\n",
    "    dataset_train = FaceSynthetics(remote_train, local_train, shuffle)\n",
    "    dataset_test  = FaceSynthetics(remote_test, local_test, shuffle)\n",
    "    \n",
    "    batch_size = 2\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1397b87a",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3266c0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trainer():\n",
    "    train_dataloader, test_dataloader = get_dataloaders()\n",
    "    train_epochs = \"3ep\"\n",
    "    model = ComposerDeepLabV3(\n",
    "        num_classes=num_classes, \n",
    "        backbone_arch='resnet101', \n",
    "        is_backbone_pretrained=True,\n",
    "        sync_bn=False)\n",
    "    optimizer = DecoupledAdamW(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    return Trainer(\n",
    "        model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        eval_dataloader=test_dataloader,\n",
    "        max_duration=train_epochs,\n",
    "        optimizers=optimizer,\n",
    "        device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48292a0d",
   "metadata": {},
   "source": [
    "## Putting it all Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77470859",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f082a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = make_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ecd9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.perf_counter()\n",
    "trainer.fit()\n",
    "end_time = time.perf_counter()\n",
    "print(f\"It took {end_time - start_time:0.4f} seconds to train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f219ed4",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66663796",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(out_root)\n",
    "!rm dataset.zip\n",
    "!rm -rf dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc374b6",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Congrats! We've trained our FaceSynthetics model on a streaming dataset!\n",
    "\n",
    "Now that we're done, we can explore some additional speedups, like\n",
    "* running against a full dataset\n",
    "* using composer algorithms\n",
    "* building a multi-gpu trainer\n",
    "\n",
    "Happy training!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
